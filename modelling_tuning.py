# -*- coding: utf-8 -*-
"""modelling_tuning

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13JVXjDu2jlY5xvAvol_kx8hlBtoqMYtf
"""

# Commented out IPython magic to ensure Python compatibility.
# 1) CLONE REPO GITHUB
!rm -rf Eksperimen_SML_Muhammad-Rafi-Insani
!git clone https://github.com/rafi1n/Eksperimen_SML_Muhammad-Rafi-Insani.git
# %cd Eksperimen_SML_Muhammad-Rafi-Insani/Membangun_model
!ls -la

# 2) INSTALL DEPENDENCIES
!pip -q install --upgrade pip
!pip -q install pandas numpy scikit-learn mlflow dagshub matplotlib joblib

# 3) SET ENV VAR UNTUK DAGSHUB
import os
os.environ["DAGSHUB_REPO_OWNER"] = "rafi1n"
os.environ["DAGSHUB_REPO_NAME"]  = "Eksperimen_SML_Muhammad-Rafi-Insani"

# 4) LOGIN DAGSHUB
from getpass import getpass
import os
token = getpass("Paste DAGSHUB TOKEN (tidak tampil): ")
os.environ["DAGSHUB_TOKEN"] = token
print("Token set.")

# 5) INISIALISASI DAGSHUB MLFLOW
import dagshub
repo_owner = os.environ["DAGSHUB_REPO_OWNER"]
repo_name  = os.environ["DAGSHUB_REPO_NAME"]
dagshub.init(repo_owner=repo_owner, repo_name=repo_name, mlflow=True)
print("DagsHub MLflow initialized.")

"""Baseline Run"""

# 6A) BASELINE TRAINING (manual logging)
import os
import json
from datetime import datetime
import numpy as np
import pandas as pd
import mlflow
import mlflow.sklearn
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.linear_model import LogisticRegression

DATA_PATH = "titanic_processed.csv"
TARGET = "Survived"
df = pd.read_csv(DATA_PATH)
X = df.drop(columns=[TARGET]).copy()
y = df[TARGET].copy()

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y)

num_cols = X.select_dtypes(include=[np.number]).columns.tolist()
cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()

numeric_tf = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())])

categorical_tf = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent"))])

preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_tf, num_cols),
        ("cat", categorical_tf, cat_cols),
    ],
    remainder="drop")

pipe = Pipeline(steps=[
    ("preprocess", preprocessor),
    ("model", LogisticRegression(max_iter=2000))])

experiment_name = f"titanic_colab_baseline_{datetime.now().strftime('%Y%m%d')}"
mlflow.set_experiment(experiment_name)
with mlflow.start_run(run_name="baseline_logreg_colab"):
    # params
    mlflow.log_param("model", "LogisticRegression")
    mlflow.log_param("test_size", 0.2)
    mlflow.log_param("random_state", 42)
    mlflow.log_param("n_rows", df.shape[0])
    mlflow.log_param("n_features_before", X.shape[1])
    # train
    pipe.fit(X_train, y_train)
    # eval
    y_pred = pipe.predict(X_test)
    try:
        y_proba = pipe.predict_proba(X_test)[:, 1]
        auc = roc_auc_score(y_test, y_proba)
    except Exception:
        auc = None
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, zero_division=0)
    rec = recall_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)
    mlflow.log_metric("accuracy", acc)
    mlflow.log_metric("precision", prec)
    mlflow.log_metric("recall", rec)
    mlflow.log_metric("f1", f1)
    if auc is not None:
        mlflow.log_metric("roc_auc", auc)
    # log model
    mlflow.sklearn.log_model(pipe, artifact_path="model")
    # extra artifact:schema
    schema = {
        "target": TARGET,
        "features": list(X.columns),
        "dtypes": {c: str(df[c].dtype) for c in df.columns}}
    os.makedirs("colab_artifacts", exist_ok=True)
    schema_path = "colab_artifacts/schema.json"
    with open(schema_path, "w", encoding="utf-8") as f:
        json.dump(schema, f, indent=2)
    mlflow.log_artifact(schema_path, artifact_path="extras")
print("Baseline done. Cek tab Experiments/MLflow UI di DagsHub.")

"""Advanced Run (tuning+manual logging+2+artefak)"""

# 6B) ADVANCED TUNING + MANUAL LOGGING + EXTRA ARTIFACTS
import json
from datetime import datetime
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import mlflow
import mlflow.sklearn
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, confusion_matrix, classification_report)
from sklearn.ensemble import RandomForestClassifier
DATA_PATH = "titanic_processed.csv"
TARGET = "Survived"

df = pd.read_csv(DATA_PATH)
X = df.drop(columns=[TARGET]).copy()
y = df[TARGET].copy()
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y)

num_cols = X.select_dtypes(include=[np.number]).columns.tolist()
cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()

numeric_tf = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())])
categorical_tf = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent"))])
preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_tf, num_cols),
        ("cat", categorical_tf, cat_cols),
    ],
    remainder="drop")
pipe = Pipeline(steps=[
    ("preprocess", preprocessor),
    ("model", RandomForestClassifier(random_state=42))])
param_grid = {
    "model__n_estimators": [100, 200, 400],
    "model__max_depth": [None, 4, 6, 8, 12],
    "model__min_samples_split": [2, 5, 10],
    "model__min_samples_leaf": [1, 2, 4],
    "model__max_features": ["sqrt", "log2"],}
grid = GridSearchCV(
    estimator=pipe,
    param_grid=param_grid,
    scoring="f1",
    cv=5,
    n_jobs=-1,
    verbose=0)

experiment_name = f"titanic_colab_advanced_{datetime.now().strftime('%Y%m%d')}"
mlflow.set_experiment(experiment_name)
os.makedirs("colab_artifacts", exist_ok=True)

def save_confusion_matrix(cm, out_path):
    plt.figure()
    plt.imshow(cm)
    plt.title("Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.xticks([0,1], ["0","1"])
    plt.yticks([0,1], ["0","1"])
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            plt.text(j, i, str(cm[i, j]), ha="center", va="center")
    plt.tight_layout()
    plt.savefig(out_path, dpi=150)
    plt.close()
with mlflow.start_run(run_name="rf_gridsearch_manual_logging_colab"):
    # log params dasar
    mlflow.log_param("model", "RandomForestClassifier")
    mlflow.log_param("tuning", "GridSearchCV")
    mlflow.log_param("scoring", "f1")
    mlflow.log_param("cv", 5)
    mlflow.log_param("test_size", 0.2)
    mlflow.log_param("random_state", 42)
    # train + tuning
    grid.fit(X_train, y_train)
    best_est = grid.best_estimator_
    best_params = grid.best_params_
    best_cv_f1 = float(grid.best_score_)
    for k, v in best_params.items():
        mlflow.log_param(f"best_{k}", v)
    mlflow.log_metric("best_cv_f1", best_cv_f1)
    # test eval
    y_pred = best_est.predict(X_test)
    try:
        y_proba = best_est.predict_proba(X_test)[:, 1]
        auc = roc_auc_score(y_test, y_proba)
    except Exception:
        auc = None
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, zero_division=0)
    rec = recall_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)
    mlflow.log_metric("test_accuracy", acc)
    mlflow.log_metric("test_precision", prec)
    mlflow.log_metric("test_recall", rec)
    mlflow.log_metric("test_f1", f1)
    if auc is not None:
        mlflow.log_metric("test_roc_auc", auc)
    # log model
    mlflow.sklearn.log_model(best_est, artifact_path="model")

    #XTRA ARTIFACTS (>=2)
    # 1) confusion matrix image
    cm = confusion_matrix(y_test, y_pred)
    cm_path = "colab_artifacts/confusion_matrix.png"
    save_confusion_matrix(cm, cm_path)
    mlflow.log_artifact(cm_path, artifact_path="extras")
    # 2) classification report txt
    rep = classification_report(y_test, y_pred, digits=4, zero_division=0)
    rep_path = "colab_artifacts/classification_report.txt"
    with open(rep_path, "w", encoding="utf-8") as f:
        f.write(rep)
    mlflow.log_artifact(rep_path, artifact_path="extras")
    # 3) metadata json
    meta = {
        "target": TARGET,
        "features": list(X.columns),
        "dtypes": {c: str(df[c].dtype) for c in df.columns},
        "best_params": {k: str(v) for k, v in best_params.items()},
    }
    meta_path = "colab_artifacts/run_metadata.json"
    with open(meta_path, "w", encoding="utf-8") as f:
        json.dump(meta, f, indent=2)
    mlflow.log_artifact(meta_path, artifact_path="extras")
print("Advanced tuning done. Buka DagsHub -> Experiments / MLflow UI untuk lihat run + artifacts.")